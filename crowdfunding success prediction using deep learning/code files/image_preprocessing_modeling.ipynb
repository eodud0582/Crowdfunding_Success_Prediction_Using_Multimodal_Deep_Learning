{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import h5py\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorflow 버전 확인\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# GPU 사용 여부 확인\n",
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 데이터 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미 훈련된 VGG16 모델을 사용한 전이 학습 및 특성 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수집된 총 이미지 개수 : 153,576\n",
    "# 이미지가 존재하지 않는 이미지 파일 : 1\n",
    "# 제거 후 총 이미지 개수 : 153,575\n",
    "# 데이터 양이 충분히 많기에 image augmentation은 할 필요가 없다고 판단\n",
    "# 특성추출이 수집된 이미지 데이터에 더 적합하도록 맞추기 위해 fine-tuning방식 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7fcb84d71c90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcbb43b9ad0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcb0abde950>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fcb0abdeed0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcb00120710>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcb00120110>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fcb001339d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcb00139890>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcb00144f90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcb0014ac50>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fcb0014ffd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcb00156e50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcb000e2d50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcb000e5cd0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fcb000eba50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcb000efc50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcb000fbb50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fcb000feb10>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fcb00105c50>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 미세조정(fine-tuning) 시도\n",
    "\n",
    "conv_base.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block5_conv1, block5_conv2, block5_conv3 --> fine-tuning\n",
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 7,079,424\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#디렉토리에서 이미지 로드 및 generator 생성\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 512\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    \"\"\"\n",
    "    디렉토리로 부터 Image들을 읽어 들여 VGG16의 특성추출 레이어를 이용해 이미지 특성 추출\n",
    "    directory: 이미지를 가져올 디렉토리\n",
    "    sample_count: 학습시킬 이미지 개수 (이걸로 총 몇개의 이미지를 만들지)\n",
    "    \"\"\"\n",
    "    #추출된 이미지 특성들을 저장할 ndarray변수.  array 크기: (개수, conv_base의 출력 shape)\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "\n",
    "    #ImageDataGenerator를 이용해 이미지 가져오기.\n",
    "    generator = datagen.flow_from_directory(directory, #디렉토리로부터 이미지를 읽어와서\n",
    "                                        target_size=(150, 150), #모든 이미지들 사이즈를 150, 150으로 맞출거다\n",
    "                                        batch_size=batch_size, #한번에 몇장 만들지\n",
    "                                        class_mode=None)\n",
    "    \n",
    "    \n",
    "    i = 0  #predict한 이미지 수를 저장해 sample_count보다 커지면 break 한다.\n",
    "    for inputs_batch in generator: #input data와 label이 나올거잖아, 고양이 관련 데이터면 그게 고양이다라는 것도 같이 나오니까\n",
    "        #VGG16을 통해 나오는 특성맵을 저장\n",
    "        feature_map_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = feature_map_batch #index\n",
    "        \n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, generator.filenames #우리가 가져온 이미지들이 VGG16 layer를 통과하고 거쳐 나온 feature map들이 들어있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 153575 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eodud0582/anaconda3/envs/tensorflow/lib/python3.7/site-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    }
   ],
   "source": [
    "# image feature extraction\n",
    "# 이미지 특성 추출\n",
    "try:\n",
    "    image_dir = './image_2015_2019_folder'\n",
    "    features, filenames = extract_features(image_dir, 153575)\n",
    "    #features.shape\n",
    "    image_data = features.reshape(153575, 4*4*512)\n",
    "    #image_data.shape\n",
    "    df_image = pd.DataFrame(image_data)\n",
    "    try:\n",
    "        df_image['index'] = [filename.split('/')[1].split('.')[0] for filename in filenames]\n",
    "        df_image['index'] = df_image['index'].astype('int64')\n",
    "        df_image = df_image.set_index('index').sort_index().reset_index()\n",
    "        df_image.to_pickle('image_feature_df.pkl')\n",
    "    except Exception as e:\n",
    "        df_image['index'] = filenames\n",
    "        df_image.to_pickle('image_feature_df.pkl')\n",
    "        \n",
    "        filename_split_error = []\n",
    "        filename_split_error.append(e)\n",
    "        split_error = pd.DataFrame(filename_split_error, columns=['error'])\n",
    "        split_error.to_csv('filename_split_error.csv', index=False)\n",
    "\n",
    "except Exception as ex:\n",
    "    error_list = []\n",
    "    error_list.append(ex)\n",
    "    error = pd.DataFrame(error_list, columns=['error'])\n",
    "    error.to_csv('image_feature_extraction_failed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "image_df = pd.read_pickle('image_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153575, 8193)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 크기가 너무 큽니다. 10GB를 넘어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153575,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결국 모든 컬럼을 --> 평균으로 계산하여 컬럼을 하나로만 만들었습니다\n",
    "avg_image_df = image_df.mean(1)\n",
    "avg_image_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(avg_image_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_image_df.to_pickle('avg_image_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
